{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neRPQTgCU8ff",
        "outputId": "ad133bd2-25ad-4b75-9b70-81d3619eedaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.26.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_preprocessing # install keras_preprocessing package\n",
        "import tensorflow as tf\n",
        "import keras_preprocessing #import keras_preprocessing\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Instead of importing TensorBoard from keras.callbacks, we will use it from tf.keras.callbacks\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.models import Sequential # Changed from keras.models to tensorflow.keras.models\n",
        "# Import layers from tensorflow.keras.layers\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "# BatchNormalization is now imported directly from tensorflow.keras.layers\n",
        "#from keras.layers.normalization import BatchNormalization # This line is removed\n",
        "from tensorflow.keras.optimizers import Adam # Changed from keras.optimizers to tensorflow.keras.optimizers\n",
        "import keras\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-I_cxIrVVA5",
        "outputId": "2617fbf4-5454-4e12-d3ec-6a9df2edc4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4HLpGh9VNut"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_dir = \"/content/drive/My Drive/potato dis/train\"\n",
        "test_dir = \"/content/drive/My Drive/potato dis/test\"\n",
        "validation_dir = \"/content/drive/My Drive/potato dis/val\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = train_dir\n",
        "class_names = os.listdir(dataset_path)\n",
        "print(\"Classes:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhDgmarWLB4j",
        "outputId": "f19c1364-d6bf-4c94-a9c0-71339708d795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Potato___Late_blight', 'Potato___healthy', 'Potato___Early_blight']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBcatUreapEM"
      },
      "outputs": [],
      "source": [
        "ROT_RANGE = 10\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_gen = ImageDataGenerator(\n",
        "rescale = 1./255,\n",
        "rotation_range = ROT_RANGE,\n",
        "width_shift_range=0.2,\n",
        "height_shift_range=0.2,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "horizontal_flip=True,\n",
        "fill_mode='nearest')\n",
        "\n",
        "valid_gen = ImageDataGenerator(rescale = 1./255)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu4Cspslasgn",
        "outputId": "d1a8d8cf-fd36-4791-b7fc-0de9bdb757bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1506 images belonging to 3 classes.\n",
            "Found 215 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "TARGET_SIZE = (224,224)\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "SEED = 42\n",
        "\n",
        "#Data Iterator\n",
        "train_data = train_gen.flow_from_directory(\n",
        "train_dir,\n",
        "target_size = TARGET_SIZE,\n",
        "class_mode = 'categorical',\n",
        "color_mode = \"rgb\",\n",
        "batch_size = TRAIN_BATCH_SIZE,\n",
        "shuffle = True,\n",
        "seed = SEED\n",
        ")\n",
        "\n",
        "valid_data = valid_gen.flow_from_directory(\n",
        "validation_dir,\n",
        "target_size = TARGET_SIZE,\n",
        "class_mode = 'categorical',\n",
        "color_mode = \"rgb\",\n",
        "batch_size = VALID_BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDx89mgTbm7f",
        "outputId": "a3346aac-b4fc-472a-ba74-70f860fb704b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "base_model = keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=[224, 224, 3])\n",
        "\n",
        "\n",
        "x = keras.layers.Flatten() (base_model.output)\n",
        "x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "x = keras.layers.Dropout(0.25)(x)\n",
        "output = keras.layers.Dense(3, activation='softmax')(x)\n",
        "model = keras.models.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# The newly added layers are initialized with random values.\n",
        "# Make sure based model remain unchanged until newly added layers weights get reasonable values.\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2J5njPib3aD"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "#LEARNING_RATE = 0.001\n",
        "\n",
        "# Change 'lr' to 'learning_rate'\n",
        "opt = Adam(learning_rate = LEARNING_RATE)\n",
        "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkV587mHcFkH",
        "outputId": "1148ca97-7c8f-4b2d-a800-50895b7cab8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1316s\u001b[0m 24s/step - accuracy: 0.6483 - loss: 0.8216 - val_accuracy: 0.8837 - val_loss: 0.3308\n",
            "Epoch 2/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 471ms/step - accuracy: 0.8740 - loss: 0.3730 - val_accuracy: 0.9256 - val_loss: 0.2539\n",
            "Epoch 3/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 483ms/step - accuracy: 0.9004 - loss: 0.2913 - val_accuracy: 0.9535 - val_loss: 0.1890\n",
            "Epoch 4/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 475ms/step - accuracy: 0.9062 - loss: 0.2407 - val_accuracy: 0.9535 - val_loss: 0.1746\n",
            "Epoch 5/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 459ms/step - accuracy: 0.9274 - loss: 0.2194 - val_accuracy: 0.9721 - val_loss: 0.1540\n",
            "Epoch 6/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 469ms/step - accuracy: 0.9402 - loss: 0.1777 - val_accuracy: 0.9442 - val_loss: 0.1540\n",
            "Epoch 7/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.9288 - loss: 0.1891 - val_accuracy: 0.9581 - val_loss: 0.1472\n",
            "Epoch 8/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 489ms/step - accuracy: 0.9391 - loss: 0.1736 - val_accuracy: 0.9628 - val_loss: 0.1375\n",
            "Epoch 9/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 488ms/step - accuracy: 0.9476 - loss: 0.1537 - val_accuracy: 0.9581 - val_loss: 0.1342\n",
            "Epoch 10/10\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 485ms/step - accuracy: 0.9448 - loss: 0.1675 - val_accuracy: 0.9302 - val_loss: 0.1596\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x = train_data, validation_data=valid_data,epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9tDJz_5jaPW"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate (This ensures the base model weights do not change a lot)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSESW89Cjrxz",
        "outputId": "f7a697b7-d208-49f2-fcc2-cea4e680b15e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 637ms/step - accuracy: 0.9919 - loss: 0.0336 - val_accuracy: 0.9860 - val_loss: 0.0374\n",
            "Epoch 2/5\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 616ms/step - accuracy: 0.9968 - loss: 0.0166 - val_accuracy: 0.9814 - val_loss: 0.0519\n",
            "Epoch 3/5\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 619ms/step - accuracy: 0.9922 - loss: 0.0202 - val_accuracy: 0.9767 - val_loss: 0.0960\n",
            "Epoch 4/5\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 671ms/step - accuracy: 0.9902 - loss: 0.0253 - val_accuracy: 0.9907 - val_loss: 0.0180\n",
            "Epoch 5/5\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 634ms/step - accuracy: 0.9899 - loss: 0.0344 - val_accuracy: 0.9907 - val_loss: 0.0199\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x = train_data, validation_data=valid_data,epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3TO3aEgTldSM",
        "outputId": "a82c2a7d-89f0-4c1a-9778-5a2834327a71"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import save_model\n",
        "model.save(\"/content/drive/My Drive/potato dis/vgg16(2).h5\")\n",
        "  # Save the model in HDF5 format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xGPPGGevmH5W",
        "outputId": "3816c074-1944-4ee8-d5a8-77a2e2482da8"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_4d0d5984-927e-42b0-914a-3c77dc064ea7\", \"vgg16(1).h5\", 169212072)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/drive/My Drive/potato dis/vgg16(1).h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouevYcjjekv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c2baad-2422-4649-95ac-6fce9e927cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)  # Example: 2.14.0\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}